### Literature Survey
### RNN: Evolution And Limitations In Generating Text Sequences

#### Abstract
Recurrent Neural Networks (RNNs) are compelling sequence models that are capable of learning features and long-term dependencies from data. A well-trained RNN can model any dynamical system; however, they do not enjoy widespread use because it is challenging to train them properly. Issues in learning long-term dependencies, mostly impede training RNNs. This literature survey discusses RNNs, briefly describing its architecture and types. The survey describes a few critical challenges faced by the researchers, along with the architectural advances made in the field of RNN research. Lastly, the survey concludes by discussing the current state of research and its future discourse.
